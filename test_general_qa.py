#!/usr/bin/env python3
"""
Test script for the enhanced Elch agent with general question answering capabilities.
"""

import os
import sys
import json

# Add the current directory to Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from universal_assistant import classify_question_type, answer_general_question

def test_question_classification():
    """Test the question classification functionality."""
    print("ğŸ§ª Testing Question Classification")
    print("=" * 50)

    test_cases = [
        # General questions
        ("What is the capital of France?", "general"),
        ("Explain how photosynthesis works", "general"),
        ("What are the benefits of exercise?", "general"),
        ("Who wrote Romeo and Juliet?", "general"),
        ("What is machine learning?", "general"),

        # Task-based requests
        ("Book a flight to New York", "task"),
        ("Search for restaurants in downtown", "task"),
        ("Fill out this online form", "task"),
        ("Order groceries online", "task"),
        ("Check my email inbox", "task"),
    ]

    correct = 0
    total = len(test_cases)

    for question, expected in test_cases:
        try:
            result = classify_question_type(question)
            status = "âœ…" if result == expected else "âŒ"
            print(f"{status} '{question}' â†’ {result} (expected: {expected})")
            if result == expected:
                correct += 1
        except Exception as e:
            print(f"âŒ '{question}' â†’ ERROR: {e}")

    accuracy = correct / total * 100
    print(f"\nğŸ“Š Classification Accuracy: {correct}/{total} ({accuracy:.1f}%)")
    return accuracy >= 80  # Consider it passing if 80% or better

def test_general_answers():
    """Test the general question answering functionality."""
    print("\nğŸ§ª Testing General Question Answering")
    print("=" * 50)

    test_questions = [
        "What is the largest planet in our solar system?",
        "Explain the concept of gravity in simple terms",
        "What are the main ingredients in a traditional pizza?",
        "Who was Albert Einstein?",
        "What is the difference between weather and climate?"
    ]

    for question in test_questions:
        try:
            print(f"\nâ“ Question: {question}")
            answer = answer_general_question(question)
            print(f"ğŸ¤– Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}")
            print("âœ… Successfully answered")
        except Exception as e:
            print(f"âŒ Error answering question: {e}")

def test_mixed_scenario():
    """Test a mixed scenario with both general questions and tasks."""
    print("\nğŸ§ª Testing Mixed Scenario")
    print("=" * 50)

    mixed_inputs = [
        "What is artificial intelligence?",
        "Find me a good Italian restaurant nearby",
        "Explain blockchain technology",
        "Book an appointment with my doctor",
        "What are the health benefits of meditation?",
        "Search for flights from New York to London"
    ]

    for user_input in mixed_inputs:
        try:
            q_type = classify_question_type(user_input)
            print(f"\nğŸ“ Input: {user_input}")
            print(f"ğŸ·ï¸  Type: {q_type}")

            if q_type == "general":
                answer = answer_general_question(user_input)
                print(f"ğŸ¤– Answer: {answer[:150]}{'...' if len(answer) > 150 else ''}")
            else:
                print("ğŸ”§ Would proceed with tool-based execution")

        except Exception as e:
            print(f"âŒ Error processing: {e}")

def main():
    """Run all tests."""
    print("ğŸš€ Testing Enhanced Elch Agent - General Question Answering")
    print("=" * 60)

    try:
        # Test classification accuracy
        classification_passed = test_question_classification()

        # Test general question answering
        test_general_answers()

        # Test mixed scenario
        test_mixed_scenario()

        print("\n" + "=" * 60)
        if classification_passed:
            print("âœ… All tests completed successfully!")
            print("ğŸ‰ Your agent can now answer general questions using Gemini API!")
        else:
            print("âš ï¸  Classification accuracy could be improved, but basic functionality works.")
            print("ğŸ’¡ Consider fine-tuning the classification prompts for better accuracy.")

        print("\nğŸ“‹ Features Added:")
        print("   â€¢ Question type classification (general vs task)")
        print("   â€¢ Direct answering of general questions using Gemini API")
        print("   â€¢ Context-aware responses using agent memory")
        print("   â€¢ Seamless integration with existing tool-based workflows")
        print("   â€¢ Enhanced user experience for informational queries")

    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
